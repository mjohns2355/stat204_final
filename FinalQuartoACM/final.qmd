---
title: "An Intentional AI for Hanabi: Reproduction"
format: pdf
author:
  - name: MJ Johns
  - name: Adam Khan

bibliography: references.bib
---

# Introduction

In this reproduction, we consider the paper "*An intentional AI for hanabi*" [@eger_intentional_2017] and propose the following research questions which reproduce and extend the findings of the prior paper:

-   RQ1: Does an intentional AI agent perform better in a collaborative game with a human than a baseline AI agent? (as measured by score)

-   RQ2: Is the player’s perception of the AI agent (e.g. perceived skill and/or enjoyment of playing together) correlated with higher score, regardless of implementation?

-   RQ3: Can we use Machine Learning to predict human responses to improve game-playing AI for more compatible cooperation?

### Background and Motivation

Game-playing AI has proven to be a useful test-bed for exploring decision-making AI implementations, and has attracted a wide range of researchers and research interests [@yin_ai_2023; @hu_games_2024]. Similarly, AI within games offer a valuable opportunity to understand human perception of interacting, and collaborating, with AI [@laird_research_2002; @yannakakis_ai_2005]. As we rapidly approach a state where humans and AI interact and cooperate on a daily basis, it is becoming increasingly important to (1) develop AIs that meaningfully cooperate with humans, and (2) understand what aspects of human-AI interaction are enjoyable, challenging, or unpleasant for humans. With this paper, we aim to contribute to further understanding AI implementations and human-AI interaction through an analysis of an intentional AI for the game of hanabi.

### Dataset Description

(source, size, key variables)

### Study Objectives

# Exploratory Data Analysis (≈1-1.5 pages)

-   Summary statistics

-   Data visualization (2-3 key plots)

-   Data quality assessment (missing values, outliers, distributions)

-   Preliminary insights that inform modeling choices

```{r}
#| echo: false
#| warning: false
#| error: false

# add some libraries
library(ggplot2)
library(dplyr)

# Load the survey ratings data
survey_response <- readr::read_csv('https://raw.githubusercontent.com/yawgmoth/HanabiData/refs/heads/master/participants.csv')

# Preview the data
# summary(survey_response)

# cleanup and remove NAs
survey_complete <- survey_response[complete.cases(survey_response),]


# plot AI implementation vs score
ggplot(survey_complete, aes(x = ai, y = score)) +
  geom_boxplot()

# plot percieved skill vs score
ggplot(survey_complete, aes(x = skill, y = score)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)


# aggregate score by perceived skill of AI
score_skill <- aggregate(score ~ skill, data = survey_complete, FUN = mean)

# aggregated score by whether they liked the AI
score_like <- aggregate(score ~ like, data = survey_complete, FUN = mean)

# aggregate score by how intentional they thought the AI was
score_intention <- aggregate(score ~ intention, data = survey_complete, FUN = mean)

# aggregate score by which AI was used
score_ai <- aggregate(score ~ ai, data = survey_complete, FUN = mean)

# plot aggregated score by perceived skill
plot(score_skill)


# plot aggregated score by AI implementation
# plot(score_ai)

```

**Track 1 (Paper Reproduction) should include:**

-   A combination of original EDA and useful pieces of the EDA presented in the paper. If you use/reproduce a plot from the original paper in your report, give credit to the authors in the source.

# Methods (≈1-1.5 pages)

**Track 1 (Paper Reproduction) should include:**

-   Short explanation of the methods used in the original paper

-   Proposed extension or alternative model (following the next section details)

**Both tracks should include:**

-   **Statistical models used** with mathematical notation where appropriate

    -   For regression: specify model equation, link function (if applicable), assumptions

    -   For PCA: explain dimensionality reduction approach

    -   For clustering: describe method and distance metric

    -   For regularization: specify penalty type and selection procedure

-   **Why these methods?** Connect to research questions and data structure

-   Software and key R packages used (don’t forget to cite the R packages)

# Results (≈2-2.5 pages)

```{r}
#| echo: false
#| warning: false
#| error: false

# anova with just AI

model <- aov(score ~ ai, survey_complete)
#summary(model)

# need AI and skill to be factors
survey_complete$ai <- factor(survey_complete$ai)
survey_complete$skill <- factor(survey_complete$skill)

# anove with both AI and skill plus interaction
model2 <- aov(score ~ skill + ai + skill:ai, survey_complete)
#summary(model2)

# anova with just skill (as factor)
model3 <- aov(score ~ skill, survey_complete)
#summary(model3)

# anova with just AI (as factor)
model4 <- aov(score ~ ai, survey_complete)
summary(model4)

# Tukey test compares all pairwise options from the ANOVA
tukey_results <- TukeyHSD(model4)
print(tukey_results) 


```

**Track 1 (Paper Reproduction) should include:**

-   Summary of reproduction success/challenges

-   What did the original authors do well? What could be improved?

-   Summary of results with proposed model following the next section details.

**Both tracks should include:**

-   Model fitting and diagnostics

    -   Assumption checking (residual plots, normality tests, etc.)

    -   Model comparison (if applicable)

    -   Goodness-of-fit measures

-   Parameter interpretation with confidence intervals where appropriate

-   Key findings presented with visualizations

### Discussion & Conclusion (≈0.75-1 page)

**Both tracks should include:**

-   Answers to research questions with supporting evidence

-   Practical implications or insights

-   Limitations and assumptions

-   Future directions

**Track 1 (Reproduction) should include:**

-   A summary of what could be improved in the original paper and how your new analysis does exactly that.

# References